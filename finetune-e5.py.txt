import json

from llama_index.core import SimpleDirectoryReader
from llama_index.core.node_parser import SentenceSplitter
from llama_index.core.schema import MetadataMode
from llama_index.finetuning import generate_qa_embedding_pairs
from llama_index.core.evaluation import EmbeddingQAFinetuneDataset

TRAIN_FILES = ["pdfs/MICROSOFT_2021_10K.pdf", "pdfs/JPMORGAN_2023Q2_10Q.pdf", "pdfs/APPLE_2019_10K.pdf", "pdfs/EBAY_2016_10K.pdf", "pdfs/MICROSOFT_2015_10K.pdf", "pdfs/AMD_2017_10K.pdf", "pdfs/ADOBE_2016_10K.pdf", "pdfs/ADOBE_2015_10K.pdf", "pdfs/GENERALMILLS_2019_10K.pdf", "pdfs/PG_E_2021_10K.pdf", "pdfs/CORNING_2022_10K.pdf", "pdfs/VERIZON_2020_10K.pdf", "pdfs/JPMORGAN_2021Q2_10Q.pdf", "pdfs/ULTABEAUTY_2023Q1_EARNINGS.pdf", "pdfs/KRAFTHEINZ_2021_10K.pdf", "pdfs/GENERALMILLS_2020_10K.pdf", "pdfs/INTEL_2018_10K.pdf", "pdfs/JPMORGAN_2022Q3_10Q.pdf", "pdfs/BOEING_2018_10K.pdf", "pdfs/3M_2015_10K.pdf", "pdfs/EBAY_2023Q2_8K.pdf", "pdfs/NETFLIX_2017_10K.pdf", "pdfs/FEDEX_2023_annualreport.pdf", "pdfs/AMD_2016_10K.pdf", "pdfs/BLOCK_2015_10K.pdf", "pdfs/PG_E_2023_EARNINGS_dated-2023-05-04.pdf", "pdfs/NETFLIX_2021_10K.pdf", "pdfs/MCDONALDS_8K_dated-2023-01-06.pdf", "pdfs/INTEL_2016_10K.pdf", "pdfs/AES_2020_10K.pdf", "pdfs/PG_E_2023_EARNINGS-dated-2023-07-27.pdf", "pdfs/3M_2017_10K.pdf", "pdfs/INTEL_2020_10K.pdf", "pdfs/NIKE_2021_10K.pdf", "pdfs/GENERALMILLS_2021_10K.pdf", "pdfs/BOEING_2021_10K.pdf", "pdfs/AMERICANWATERWORKS_2022_10K.pdf", "pdfs/JOHNSON_JOHNSON_2023Q2_EARNINGS.pdf", "pdfs/MGMRESORTS_2019_10K.pdf", "pdfs/CORNING_2016_10K.pdf", "pdfs/PG_E_2015_10K.pdf", "pdfs/PFIZER_2022_10K.pdf", "pdfs/CVSHEALTH_2016_10K.pdf", "pdfs/BESTBUY_2022_10K.pdf", "pdfs/BESTBUY_2018_10K.pdf", "pdfs/AMERICANWATERWORKS_2023Q2_10Q.pdf", "pdfs/ADOBE_2022Q2_10Q.pdf", "pdfs/BESTBUY_2020_10K.pdf", "pdfs/PG_E_2023Q3_10Q.pdf", "pdfs/PEPSICO_2017_10K.pdf", "pdfs/LOCKHEEDMARTIN_2015_10K.pdf", "pdfs/EBAY_2023Q1_EARNINGS.pdf", "pdfs/ORACLE_2019_10K.pdf", "pdfs/COSTCO_2023_8K_dated-2023-01-19.pdf", "pdfs/NETFLIX_2015_10K.pdf", "pdfs/PFIZER_2015_10K.pdf", "pdfs/ORACLE_2020_10K.pdf", "pdfs/NETFLIX_2016_10K.pdf", "pdfs/AMERICANEXPRESS_2022_10K.pdf", "pdfs/SALESFORCE_2023Q3_10Q.pdf", "pdfs/BESTBUY_2021_10K.pdf", "pdfs/AMD_2015_10K.pdf", "pdfs/MGMRESORTS_2018_10K.pdf"]

VAL_FILES = ["pdfs/PEPSICO_2015_10K.pdf", "pdfs/FEDEX_2023_10K.pdf", "pdfs/FOOTLOCKER_2022_8K_dated_2022-08-19.pdf", "pdfs/EBAY_2023Q1_8K.pdf", "pdfs/BLOCK_2020_10K.pdf", "pdfs/BLOCK_2016_10K.pdf", "pdfs/ACTIVISIONBLIZZARD_2021_10K.pdf", "pdfs/MICROSOFT_2023_10K.pdf"]

TRAIN_CORPUS_FPATH = "train_corpus.json"
VAL_CORPUS_FPATH = "val_corpus.json"

def load_corpus(files, verbose=False):
    if verbose:
        print(f"Loading files {files}")

    reader = SimpleDirectoryReader(input_files=files)
    docs = reader.load_data()
    if verbose:
        print(f"Loaded {len(docs)} docs")

    parser = SentenceSplitter()
    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)

    if verbose:
        print(f"Parsed {len(nodes)} nodes")

    return nodes



train_nodes = load_corpus(TRAIN_FILES, verbose=True)
val_nodes = load_corpus(VAL_FILES, verbose=True)


from llama_index.llms.ollama import Ollama
llm = Ollama(model="qwen3:30b", request_timeout=120.0)

train_dataset = generate_qa_embedding_pairs(
	llm=Ollama(model="qwen3:8b", request_timeout=120.0),
    nodes=train_nodes,
    output_path="train_dataset.json",
)

val_dataset = generate_qa_embedding_pairs(
    llm=Ollama(model="qwen3:8b", request_timeout=120.0),
    nodes=val_nodes,
    output_path="val_dataset.json",
)

# [Optional] Load
train_dataset = EmbeddingQAFinetuneDataset.from_json("train_dataset.json")
val_dataset = EmbeddingQAFinetuneDataset.from_json("val_dataset.json")

from llama_index.finetuning import SentenceTransformersFinetuneEngine

finetune_engine = SentenceTransformersFinetuneEngine(
	train_dataset,
    model_id="intfloat/multilingual-e5-small",
    model_output_path="test_model",
    val_dataset=val_dataset,
)


finetune_engine.finetune()
embed_model = finetune_engine.get_finetuned_model()
print(embed_model)

from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.core import VectorStoreIndex
from llama_index.core.schema import TextNode
import pandas as pd


def evaluate(
    dataset,
    embed_model,
    top_k=5,
    verbose=False,
):
    corpus = dataset.corpus
    queries = dataset.queries
    relevant_docs = dataset.relevant_docs

    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]
    index = VectorStoreIndex(
        nodes, embed_model=embed_model, show_progress=True
    )
    retriever = index.as_retriever(similarity_top_k=top_k)

    eval_results = []
    for query_id, query in queries.items():
        retrieved_nodes = retriever.retrieve(query)
        retrieved_ids = [node.node.node_id for node in retrieved_nodes]
        expected_id = relevant_docs[query_id][0]
        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc

        eval_result = {
            "is_hit": is_hit,
            "retrieved": retrieved_ids,
            "expected": expected_id,
            "query": query_id,
        }
        eval_results.append(eval_result)
    return eval_results


bge = "local:intfloat/multilingual-e5-small"
bge_val_results = evaluate(val_dataset, bge)
df_bge = pd.DataFrame(bge_val_results)
hit_rate_bge = df_bge["is_hit"].mean()
hit_rate_bge

In [20]: df_bge = pd.DataFrame(bge_val_results)

In [21]: hit_rate_bge = df_bge["is_hit"].mean()
    ...: hit_rate_bge
Out[21]: np.float64(0.15625)

# FINETUNED!
finetuned = "local:test_model"
val_results_finetuned = evaluate(val_dataset, finetuned)
df_finetuned = pd.DataFrame(val_results_finetuned)
hit_rate_finetuned = df_finetuned["is_hit"].mean()
hit_rate_finetuned

In [23]: df_finetuned = pd.DataFrame(val_results_finetuned)
    ...: hit_rate_finetuned = df_finetuned["is_hit"].mean()
    ...: hit_rate_finetuned
Out[23]: np.float64(0.2596409574468085)

In [26]: df_all = pd.concat([df_bge, df_finetuned])
    ...: df_all.groupby("model").mean("is_hit")
Out[26]:
              is_hit
model
bge         0.156250
fine_tuned  0.259641

